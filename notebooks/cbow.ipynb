{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMivWD2xpxaYkpYExMdtRPQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/veekaybee/viberary/blob/main/notebooks/cbow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Wrap text results for easier display purposes\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "XQgzECnnqO7S",
        "outputId": "1f86ed8a-52f6-4363-b09f-10540833320f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CBOW Implementation of Word2Vec\n",
        "\n",
        "This is part of the background research that I'm working on for [viberary.pizza](https://viberary.pizza/).\n",
        "\n",
        "## Background \n",
        "\n",
        "[Word2vec](https://arxiv.org/abs/1301.3781) was a critical point in NLP work, building on previous work in dimensionality reduction in NLP such as tf-idf, topic modeling, and latent semantic analysis to reduce vocabulary sizes for computational complexity, and additionally, to add context by embedding similar words in the same latent space. \n",
        "\n",
        "As of 2022, it's almost been superceded by [transformers-based architectures](https://e2eml.school/transformers.html), but it's still worth understanding how it works in a historical context, as well as because there is a fair amount of it [in production in Spark](https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.ml.feature.Word2Vec.html).  "
      ],
      "metadata": {
        "id": "nsRjz7lneFzC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word2Vec Implementation\n",
        "\n",
        "There are numerous word2vec implementations in libraries like Spark and Tensorflow. There is not an exact one in PyTorch, but following[this code](https://github.com/FraLotito/pytorch-continuous-bag-of-words/blob/master/cbow.py), as well as reading about the [architecture here](https://towardsdatascience.com/word2vec-with-pytorch-implementing-original-paper-2cd7040120b0) and [here](https://jalammar.github.io/illustrated-word2vec/),  I was able to implement and understand how it works under te covers\n",
        "\n",
        "\n",
        "Original explanation in [PyTorch implementation](https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html) is here. "
      ],
      "metadata": {
        "id": "yj3p0lfyjjzo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As a starting point, we take our raw data for input. \n",
        "Our [training set for Viberary is some sample the Goodreads input dataset](https://github.com/veekaybee/viberary#input-data-sample), \n",
        "which is a string of text containing the metadata for each unique book\n",
        "id. \n",
        "\n",
        "For a single book id, it will contain the book description book title, etc. So a sample of a single book, will look like this\n",
        "\n",
        "\n",
        "```\n",
        "Raw text: All's Fairy in Love and War (Avalon: Web of Magic, #8) To Kara's astonishment, she discovers that a portal has opened in her bedroom closet and two goblins \n",
        "have fallen through! They refuse to return to the fairy realms and be drafted for an impending war. \n",
        "In an attempt to roust the pesky creatures, Kara falls through the portal, smack into the middle of a huge war.\n",
        "Kara meets Queen Selinda, who appoints Kara as a Fairy Princess and assigns her an impossible task: \n",
        "to put an end to the war using her diplomatic skills.\n",
        "```\n",
        "\n",
        "This is initially stored as a Python string. "
      ],
      "metadata": {
        "id": "NjUwUvzRltoY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our final goal in learning a Word2Vec model with CBOW is, given an input phrase over a context window, to predict the word that's missing. The context window is how many words before and after the word we care about. So, given the phrase \"Kara falls X the portal\", we should be able to predict that the correct word is \"through.\"\n",
        "\n",
        "We do this in Word2Vec by continuously sampling from the raw text over the context window, where the context window around the word is the X variable and the word itself is the target variable. \n",
        "\n",
        "For the first example, \"Kara falls the portal\" is the context and \"through\" is the response variable. Then we shift the window by 1 word and generate another entry. This is the whole of the [continuous bag of words approach.](https://arxiv.org/pdf/1301.3781.pdf)\n",
        "\n",
        "When we're first training the model, we pass these samples into the model and ask it to make a prediction on a single word given all these samples. The output is a vector of propabilities of the sample related to each word. We then compare that prediction to the actual label (I.e. for the sample \"Kara falls X the portal\" we KNOW the correct word is \"through\").\n",
        "\n",
        "We compare the actual vector (i.e. where through = 1) to the probability vector, and the difference between the two is the loss. The parameters are passed to the model across multiple epochs and continuously updated until we minimize the loss, i.e. we get as close to the predicted word as possible. \n",
        "\n",
        "In the process of doing this prediction, we create a lookup table of words, or embeddings matrix, to their vector representations. It is these vectors that become our embeddings. Andiamo!"
      ],
      "metadata": {
        "id": "St7yNIV0mRwM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torch # if you don't have it already "
      ],
      "metadata": {
        "id": "fwFv3TTwpuhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we need these bois\n",
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "QJdoRlN8ks5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Preparation"
      ],
      "metadata": {
        "id": "Zo_iXat2rKx2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First, we'll initialize our hyperparameters for the model: \n",
        "\n",
        "CONTEXT_SIZE = 2  # 2 words to the left, 2 to the right - this is our context window\n",
        "EMBEDDING_DIM = 100 # size of the embeddings matrix - we'll get to this in a bit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "49O73dGuniuC",
        "outputId": "3f61e618-c0b3-454d-f821-949e21f413a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Our tiny training dataset \n",
        "\n",
        "raw_text = \"\"\"To Kara's astonishment, she discovers that a portal has opened in her bedroom closet and two goblins have fallen through! They refuse to return to the fairy realms and be drafted for an impending war. \n",
        "In an attempt to roust the pesky creatures, Kara falls through the portal, \n",
        "smack into the middle of a huge war. Kara meets Queen Selinda, who appoints \n",
        "Kara as a Fairy Princess and assigns her an impossible task: \n",
        "to put an end to the war using her diplomatic skills.\"\"\".split()"
      ],
      "metadata": {
        "id": "Bud2ESqbp4I4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Text preprocessing get only individual words\n",
        "vocab = set(raw_text) # dedup\n",
        "vocab_size = len(vocab)"
      ],
      "metadata": {
        "id": "v0DCKTo6ntYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "fefBJxYqp1j7",
        "outputId": "a0a411ca-0b21-426e-b8fa-874192d5470e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'she', 'middle', 'put', 'be', 'discovers', 'into', 'Selinda,', 'opened', 'and', 'using', 'the', 'creatures,', 'has', 'Fairy', 'end', 'Princess', 'meets', 'realms', 'skills.', 'a', 'To', 'that', 'goblins', 'fairy', 'impending', 'appoints', 'impossible', 'astonishment,', 'fallen', 'for', 'an', 'closet', 'attempt', \"Kara's\", 'of', 'task:', 'war', 'They', 'In', 'war.', 'pesky', 'smack', 'through', 'diplomatic', 'refuse', 'assigns', 'bedroom', 'portal,', 'have', 'her', 'huge', 'as', 'to', 'Queen', 'return', 'through!', 'in', 'Kara', 'drafted', 'roust', 'two', 'portal', 'who', 'falls'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we create simple mappings of word to an index of the word\n",
        "word_to_ix = {word: ix for ix, word in enumerate(vocab)}\n",
        "ix_to_word = {ix: word for ix, word in enumerate(vocab)}"
      ],
      "metadata": {
        "id": "LRy2APaCqBT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(word_to_ix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "msMJ1G8sqEUm",
        "outputId": "810f396b-3f2c-477e-9c24-3b5df026b1e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'she': 0, 'middle': 1, 'put': 2, 'be': 3, 'discovers': 4, 'into': 5, 'Selinda,': 6, 'opened': 7, 'and': 8, 'using': 9, 'the': 10, 'creatures,': 11, 'has': 12, 'Fairy': 13, 'end': 14, 'Princess': 15, 'meets': 16, 'realms': 17, 'skills.': 18, 'a': 19, 'To': 20, 'that': 21, 'goblins': 22, 'fairy': 23, 'impending': 24, 'appoints': 25, 'impossible': 26, 'astonishment,': 27, 'fallen': 28, 'for': 29, 'an': 30, 'closet': 31, 'attempt': 32, \"Kara's\": 33, 'of': 34, 'task:': 35, 'war': 36, 'They': 37, 'In': 38, 'war.': 39, 'pesky': 40, 'smack': 41, 'through': 42, 'diplomatic': 43, 'refuse': 44, 'assigns': 45, 'bedroom': 46, 'portal,': 47, 'have': 48, 'her': 49, 'huge': 50, 'as': 51, 'to': 52, 'Queen': 53, 'return': 54, 'through!': 55, 'in': 56, 'Kara': 57, 'drafted': 58, 'roust': 59, 'two': 60, 'portal': 61, 'who': 62, 'falls': 63}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating our training data and context window\n",
        "\n",
        "def make_context_vector(context, word_to_ix):\n",
        "    idxs = [word_to_ix[w] for w in context]\n",
        "    return torch.tensor(idxs, dtype=torch.long)\n",
        "\n",
        "data = []\n",
        "for i in range(CONTEXT_SIZE, len(raw_text) - CONTEXT_SIZE):\n",
        "    context = [raw_text[i - 2], raw_text[i - 1], raw_text[i + 1], raw_text[i + 2]]\n",
        "    target = raw_text[i]\n",
        "    data.append((context, target))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "YmO3vqYfqbBG",
        "outputId": "ff06199d-6ad5-4c0d-89c1-ce1223ee81cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We have our [input, input, input, input, target]\n",
        "# based on the context window of +2 words -2 words\n",
        "# you can see how we're building words close to each other now\n",
        "print(*data[0:10], sep=\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "kJDfa4jhqjZn",
        "outputId": "6d80363a-e027-4ae5-b0fa-b79b0bb8896e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(['To', \"Kara's\", 'she', 'discovers'], 'astonishment,')\n",
            "([\"Kara's\", 'astonishment,', 'discovers', 'that'], 'she')\n",
            "(['astonishment,', 'she', 'that', 'a'], 'discovers')\n",
            "(['she', 'discovers', 'a', 'portal'], 'that')\n",
            "(['discovers', 'that', 'portal', 'has'], 'a')\n",
            "(['that', 'a', 'has', 'opened'], 'portal')\n",
            "(['a', 'portal', 'opened', 'in'], 'has')\n",
            "(['portal', 'has', 'in', 'her'], 'opened')\n",
            "(['has', 'opened', 'her', 'bedroom'], 'in')\n",
            "(['opened', 'in', 'bedroom', 'closet'], 'her')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Set Up"
      ],
      "metadata": {
        "id": "j0h7wDx2rVf5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CBOW Architecture \n",
        "\n",
        "<img width=\"344\" alt=\"Screen Shot 2023-02-14 at 3 48 16 PM\" src=\"https://user-images.githubusercontent.com/3837836/218859716-495a0a6f-aed7-40aa-aba9-5c0f1949788c.png\">\n",
        "\n",
        "We have two layers in the CBOW implementation of Word2Vec: an input Embedding layer that maps each word to a space in the embedding dictionary, a hidden linear activation layer, and then the output layer that is the proportional probabilities [softmax](https://en.wikipedia.org/wiki/Softmax_function) of all the correct words given an input window. \n",
        "\n",
        "The critical part is the first part, creating the Embeddings lookup. \n",
        "\n",
        "First, we associate each word in the vocabulary with an index, aka `{'she': 0, 'middle': 1, 'put': 2`\n",
        "\n",
        "Then, what we want to do is create an embeddings table, or matrix, that we will multiply with these indices to map each one to its correct place in relation to the other indices via a table lookup, based on how many vectors you'd like to represent the word. \n",
        "\n",
        "There is a [really good explanation](https://stats.stackexchange.com/questions/270546/how-does-keras-embedding-layer-work/305032#305032) of how these are generated: \n",
        "\n",
        "``` \n",
        "For a given word, you create a one-hot vector based on its index and multiply it by the embeddings matrix, effectively replicating a lookup. For instance, for the word \"soon\" the index is 4, and the one-hot vector is [0, 0, 0, 0, 1, 0, 0]. If you multiply this (1, 7) matrix by the (7, 2) embeddings matrix you get the desired two-dimensional embedding, which in this case is [2.2, 1.4].\n",
        "```"
      ],
      "metadata": {
        "id": "JELBoISbrbr1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CBOW(torch.nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim): # we pass in vocab_size and embedding_dim as hyperparams\n",
        "        super(CBOW, self).__init__()\n",
        "\n",
        "        # out: 1 x embedding_dim\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim) # initialize an Embedding matrix based on our inputs\n",
        "        self.linear1 = nn.Linear(embedding_dim, 128)\n",
        "        self.activation_function1 = nn.ReLU()\n",
        "\n",
        "        # out: 1 x vocab_size\n",
        "        self.linear2 = nn.Linear(128, vocab_size)\n",
        "        self.activation_function2 = nn.LogSoftmax(dim=-1)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        embeds = sum(self.embeddings(inputs)).view(1, -1)\n",
        "        out = self.linear1(embeds)\n",
        "        out = self.activation_function1(out)\n",
        "        out = self.linear2(out)\n",
        "        out = self.activation_function2(out)\n",
        "        return out\n",
        "\n",
        "    def get_word_emdedding(self, word):\n",
        "        word = torch.tensor([word_to_ix[word]])\n",
        "        # Embeddings lookup of a single word once the Embeddings layer has been optimized \n",
        "        return self.embeddings(word).view(1, -1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "x4wlRX46rXFs",
        "outputId": "ee88be3b-cd81-4c84-c612-5471bec2c8c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We initialize the model:\n",
        "\n",
        "model = CBOW(vocab_size, EMBEDDING_DIM)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "ylbLCeSQtj3u",
        "outputId": "0dd85052-3a9d-4bcf-e2d4-c36c9cff8bcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# then, we initialize the loss function \n",
        "# (aka how close our predicted word is to the actual word and how we want to minimize it using the optimizer)\n",
        "\n",
        "loss_function = nn.NLLLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "40ILyNsmuzGv",
        "outputId": "994448af-b2c4-458a-a4d1-a9a82c3d2ddc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "\n",
        "# 50 to start with, no correct answer here\n",
        "for epoch in range(50):\n",
        "    # we start tracking how accurate our intial words are\n",
        "    total_loss = 0\n",
        "\n",
        "    # for the x, y in the training data: \n",
        "    for context, target in data:\n",
        "        context_vector = make_context_vector(context, word_to_ix)\n",
        "\n",
        "        # we look at loss\n",
        "        log_probs = model(context_vector)\n",
        "\n",
        "        # we compare the loss from what the actual word is related to the probaility of the words\n",
        "        total_loss += loss_function(log_probs, torch.tensor([word_to_ix[target]]))\n",
        "\n",
        "    # optimize at the end of each epoch\n",
        "    optimizer.zero_grad()\n",
        "    total_loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    # Log out some metrics to see if loss decreases\n",
        "    print(\"end of epoch {} | loss {:2.3f}\".format(epoch, total_loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 948
        },
        "id": "f2cvfmTKvAUx",
        "outputId": "ecf9e937-7f6d-4fc8-f128-db6dce855785"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "end of epoch 0 | loss 339.945\n",
            "end of epoch 1 | loss 328.208\n",
            "end of epoch 2 | loss 317.001\n",
            "end of epoch 3 | loss 306.260\n",
            "end of epoch 4 | loss 295.829\n",
            "end of epoch 5 | loss 285.631\n",
            "end of epoch 6 | loss 275.647\n",
            "end of epoch 7 | loss 265.843\n",
            "end of epoch 8 | loss 256.195\n",
            "end of epoch 9 | loss 246.698\n",
            "end of epoch 10 | loss 237.405\n",
            "end of epoch 11 | loss 228.335\n",
            "end of epoch 12 | loss 219.449\n",
            "end of epoch 13 | loss 210.748\n",
            "end of epoch 14 | loss 202.229\n",
            "end of epoch 15 | loss 193.892\n",
            "end of epoch 16 | loss 185.753\n",
            "end of epoch 17 | loss 177.816\n",
            "end of epoch 18 | loss 170.046\n",
            "end of epoch 19 | loss 162.439\n",
            "end of epoch 20 | loss 154.975\n",
            "end of epoch 21 | loss 147.686\n",
            "end of epoch 22 | loss 140.564\n",
            "end of epoch 23 | loss 133.619\n",
            "end of epoch 24 | loss 126.860\n",
            "end of epoch 25 | loss 120.294\n",
            "end of epoch 26 | loss 113.946\n",
            "end of epoch 27 | loss 107.797\n",
            "end of epoch 28 | loss 101.887\n",
            "end of epoch 29 | loss 96.191\n",
            "end of epoch 30 | loss 90.744\n",
            "end of epoch 31 | loss 85.534\n",
            "end of epoch 32 | loss 80.584\n",
            "end of epoch 33 | loss 75.888\n",
            "end of epoch 34 | loss 71.443\n",
            "end of epoch 35 | loss 67.249\n",
            "end of epoch 36 | loss 63.302\n",
            "end of epoch 37 | loss 59.602\n",
            "end of epoch 38 | loss 56.138\n",
            "end of epoch 39 | loss 52.906\n",
            "end of epoch 40 | loss 49.888\n",
            "end of epoch 41 | loss 47.084\n",
            "end of epoch 42 | loss 44.472\n",
            "end of epoch 43 | loss 42.051\n",
            "end of epoch 44 | loss 39.801\n",
            "end of epoch 45 | loss 37.716\n",
            "end of epoch 46 | loss 35.781\n",
            "end of epoch 47 | loss 33.988\n",
            "end of epoch 48 | loss 32.323\n",
            "end of epoch 49 | loss 30.779\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, let's test to see if the model predicts the correct word using our initial input\n",
        "context = [\"Kara\",\"falls\" , \"the\", \"portal\"]\n",
        "context_vector = make_context_vector(context, word_to_ix)\n",
        "a = model(context_vector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "_Q3xzdgCvctD",
        "outputId": "49e9cc60-8e1e-4970-c104-3efdb70a5322"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Raw text: {\" \".join(raw_text)}\\n')\n",
        "print(f\"Context: {context}\\n\")\n",
        "print(f\"Prediction: {ix_to_word[torch.argmax(a[0]).item()]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "id": "zNRMxAhAvk6l",
        "outputId": "12cfb0b8-9784-4713-9d27-b12bfba080a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw text: To Kara's astonishment, she discovers that a portal has opened in her bedroom closet and two goblins have fallen through! They refuse to return to the fairy realms and be drafted for an impending war. In an attempt to roust the pesky creatures, Kara falls through the portal, smack into the middle of a huge war. Kara meets Queen Selinda, who appoints Kara as a Fairy Princess and assigns her an impossible task: to put an end to the war using her diplomatic skills.\n",
            "\n",
            "Context: ['Kara', 'falls', 'the', 'portal']\n",
            "\n",
            "Prediction: through\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Now let's get what we care about, which is the embeddings!\n",
        "print(f'Getting vectors for a sequence:\\n', model.embeddings(torch.LongTensor([1, 2, 3])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3FNZc3Ljv5e9",
        "outputId": "bf3f5eca-8d6a-4d04-f0ef-f33f41d34a59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting vectors for a sequence:\n",
            " tensor([[ 3.6677e-01,  2.8267e-02,  9.5658e-01,  9.5077e-01,  1.0641e+00,\n",
            "          8.9874e-01, -1.3958e-01, -8.8929e-01, -9.2349e-01,  2.4945e-01,\n",
            "         -1.6626e+00,  3.1749e-01,  4.5353e-01,  7.8733e-01, -1.7945e+00,\n",
            "          4.6523e-01,  1.4962e+00, -5.3494e-01,  3.3327e-01,  4.4590e-01,\n",
            "          2.7505e-01,  4.8399e-01,  4.5670e-01, -9.6859e-01,  7.5164e-01,\n",
            "          4.5564e-01, -1.8508e-01,  4.7951e-01, -5.0327e-01,  8.9468e-01,\n",
            "         -5.2872e-01, -2.8511e-01, -1.3353e-02, -4.4388e-01,  3.2415e-01,\n",
            "         -6.8152e-01, -3.0049e-01, -1.6878e+00, -1.6340e+00,  1.1231e+00,\n",
            "          1.4558e+00, -4.5023e-01, -1.1745e-01,  1.2026e+00, -1.0683e+00,\n",
            "         -3.7055e-01, -1.0187e-01,  6.5679e-01, -6.2459e-01, -6.7784e-01,\n",
            "         -8.9891e-01, -8.0431e-01,  8.7571e-01, -4.1768e-01, -6.3977e-01,\n",
            "          3.2761e-01,  1.9852e+00, -1.5843e-01, -2.9237e-01,  1.1127e+00,\n",
            "          9.7873e-01,  1.2410e+00,  1.2661e+00, -1.3038e+00, -1.8683e+00,\n",
            "         -6.9838e-01,  9.7294e-01, -5.9045e-01,  1.7600e+00, -4.2384e-01,\n",
            "         -6.1794e-01, -4.7450e-04,  1.0120e+00, -4.9126e-01, -3.7777e-01,\n",
            "         -1.1638e+00,  1.3826e-02, -8.2080e-01,  1.3369e+00, -1.3778e+00,\n",
            "         -1.1593e+00,  1.8284e+00,  1.1370e+00,  3.0711e-01,  7.0035e-01,\n",
            "         -7.2986e-01, -2.1524e+00,  7.0368e-01, -3.8547e-01,  1.7204e+00,\n",
            "          1.9402e-01,  7.6816e-01,  8.2200e-01, -1.7123e+00,  1.9162e+00,\n",
            "          3.5071e-01,  7.0243e-01, -5.3136e-01,  2.0701e-01, -1.7012e-01],\n",
            "        [ 1.8457e-01, -9.8005e-01,  1.8835e+00, -9.0263e-01,  1.9342e-03,\n",
            "          8.9444e-01,  6.7339e-01, -3.2838e-01,  5.2807e-01,  2.1467e-01,\n",
            "          2.0311e+00, -4.4473e-01,  5.2678e-01,  6.1902e-01,  1.4510e+00,\n",
            "          6.3786e-02, -1.8806e-01, -7.5348e-01,  9.0454e-01,  6.3674e-01,\n",
            "          5.7418e-01,  1.3316e+00, -1.3578e-01, -4.9159e-01,  1.7674e-01,\n",
            "         -5.7529e-01, -1.5339e+00, -2.5210e-01,  1.5591e-01, -3.4758e-02,\n",
            "          9.7976e-01,  2.3119e-01, -1.5397e+00,  2.7099e-01,  2.2308e+00,\n",
            "         -8.9181e-01, -7.5073e-01, -1.9705e+00,  1.2053e-02, -1.5014e+00,\n",
            "          2.2559e-01,  5.2383e-01, -6.6362e-01,  1.5394e+00,  2.6073e-01,\n",
            "          4.3820e-01, -3.0363e-01, -1.8602e+00, -1.1601e+00,  3.6748e-01,\n",
            "          6.0131e-01,  1.0255e+00,  6.2803e-01,  1.7424e+00,  6.3861e-01,\n",
            "         -1.3068e+00, -1.0131e-01, -9.1015e-01, -1.1763e+00, -2.7279e-01,\n",
            "          6.8290e-01,  6.2461e-01, -6.1133e-01,  1.4922e+00,  7.1820e-01,\n",
            "          2.3721e-01,  4.3717e-01,  4.8738e-01,  5.5128e-01,  4.3318e-01,\n",
            "          5.1003e-01,  5.1750e-01,  8.2711e-01, -5.5430e-01, -3.4714e-01,\n",
            "          8.6163e-01,  5.6988e-01,  2.7797e-01, -9.5815e-01, -4.0933e-01,\n",
            "         -5.4324e-01,  6.5157e-01, -6.1802e-01,  1.5340e+00, -1.2889e+00,\n",
            "         -4.2737e-01, -2.4916e-01,  7.2848e-01,  1.8303e-01,  6.9499e-01,\n",
            "          3.0259e-01,  2.4260e-01, -7.0737e-04, -4.0733e-01,  4.2134e-01,\n",
            "          1.2572e+00,  3.9979e-01,  1.6171e+00, -7.3871e-01, -4.1685e-01],\n",
            "        [ 3.4833e-01, -2.6703e+00, -1.2237e+00, -6.7714e-01,  2.8365e+00,\n",
            "          1.3369e+00,  1.2126e+00, -6.6027e-01, -2.3777e+00,  2.0408e+00,\n",
            "         -2.0692e+00, -8.9814e-01,  5.1967e-01, -9.3718e-01, -1.2553e+00,\n",
            "          1.2457e+00,  1.4166e-01,  1.0013e+00,  1.0205e+00, -5.8418e-01,\n",
            "         -1.2515e+00, -1.8427e+00,  1.4358e-01, -1.8025e+00,  1.2348e+00,\n",
            "          1.2679e-01,  1.7980e-01, -6.3570e-01,  1.0016e-01,  3.1635e-01,\n",
            "          1.5072e+00, -3.9484e-01, -4.7723e-01, -1.2306e+00, -1.5061e+00,\n",
            "          9.2145e-01,  8.3151e-01,  2.2827e-01, -1.5570e+00,  1.1989e+00,\n",
            "         -3.8061e-01, -1.0369e+00,  2.3607e-01, -6.3015e-02, -2.1210e+00,\n",
            "          2.4308e-01, -8.7681e-01,  1.5046e-01, -4.9473e-02, -8.4779e-01,\n",
            "          8.6235e-01, -3.4710e-01, -2.8452e-01, -8.3475e-01, -8.1515e-01,\n",
            "         -1.4193e+00, -7.4872e-01, -8.5501e-01, -4.4766e-01,  5.4005e-01,\n",
            "          1.3328e+00,  5.9588e-01,  1.1234e+00, -2.8081e+00,  1.3734e+00,\n",
            "          5.1211e-01,  6.6988e-01, -1.3348e+00, -7.3009e-01, -2.8725e-01,\n",
            "         -1.6588e+00, -3.9916e-01, -6.2949e-01, -4.9337e-01, -3.2343e-01,\n",
            "         -4.5827e-01,  1.9638e+00,  7.5413e-01, -3.0739e-02,  1.0232e-01,\n",
            "          3.7819e-01,  1.7623e+00, -3.8376e-01, -1.1528e+00, -3.9295e-01,\n",
            "         -7.0642e-01,  6.8652e-01,  3.8120e-01,  6.1501e-01, -4.8389e-01,\n",
            "          2.0782e+00,  1.8675e+00, -9.0364e-01,  1.5249e+00, -6.5061e-01,\n",
            "         -3.7172e-01, -1.6626e+00,  8.0428e-01,  9.0261e-01,  6.0655e-01]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Getting weights:\\n', model.embeddings.weight.data[1]) # we can get the entire matrix this way"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "L8T1UeSYzPjd",
        "outputId": "73097c5c-8e51-4ef7-d18b-f17371729f71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting weights:\n",
            " tensor([ 3.6677e-01,  2.8267e-02,  9.5658e-01,  9.5077e-01,  1.0641e+00,\n",
            "         8.9874e-01, -1.3958e-01, -8.8929e-01, -9.2349e-01,  2.4945e-01,\n",
            "        -1.6626e+00,  3.1749e-01,  4.5353e-01,  7.8733e-01, -1.7945e+00,\n",
            "         4.6523e-01,  1.4962e+00, -5.3494e-01,  3.3327e-01,  4.4590e-01,\n",
            "         2.7505e-01,  4.8399e-01,  4.5670e-01, -9.6859e-01,  7.5164e-01,\n",
            "         4.5564e-01, -1.8508e-01,  4.7951e-01, -5.0327e-01,  8.9468e-01,\n",
            "        -5.2872e-01, -2.8511e-01, -1.3353e-02, -4.4388e-01,  3.2415e-01,\n",
            "        -6.8152e-01, -3.0049e-01, -1.6878e+00, -1.6340e+00,  1.1231e+00,\n",
            "         1.4558e+00, -4.5023e-01, -1.1745e-01,  1.2026e+00, -1.0683e+00,\n",
            "        -3.7055e-01, -1.0187e-01,  6.5679e-01, -6.2459e-01, -6.7784e-01,\n",
            "        -8.9891e-01, -8.0431e-01,  8.7571e-01, -4.1768e-01, -6.3977e-01,\n",
            "         3.2761e-01,  1.9852e+00, -1.5843e-01, -2.9237e-01,  1.1127e+00,\n",
            "         9.7873e-01,  1.2410e+00,  1.2661e+00, -1.3038e+00, -1.8683e+00,\n",
            "        -6.9838e-01,  9.7294e-01, -5.9045e-01,  1.7600e+00, -4.2384e-01,\n",
            "        -6.1794e-01, -4.7450e-04,  1.0120e+00, -4.9126e-01, -3.7777e-01,\n",
            "        -1.1638e+00,  1.3826e-02, -8.2080e-01,  1.3369e+00, -1.3778e+00,\n",
            "        -1.1593e+00,  1.8284e+00,  1.1370e+00,  3.0711e-01,  7.0035e-01,\n",
            "        -7.2986e-01, -2.1524e+00,  7.0368e-01, -3.8547e-01,  1.7204e+00,\n",
            "         1.9402e-01,  7.6816e-01,  8.2200e-01, -1.7123e+00,  1.9162e+00,\n",
            "         3.5071e-01,  7.0243e-01, -5.3136e-01,  2.0701e-01, -1.7012e-01])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# And, what we actually care about is being able to look up individual words with their embeddings: \n",
        "torch.set_printoptions(threshold=10_000)\n",
        "print(f\"Embedding for Kara: {model.embeddings.weight[word_to_ix['Kara']]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "id": "CkiYM1wIvoRR",
        "outputId": "6592f79c-22b0-4a3c-9865-1946f2ebbc11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding for Kara: tensor([-0.6111,  1.5321,  2.2814,  1.3241, -1.8293,  0.6344, -0.1314, -0.9478,\n",
            "        -0.5118, -0.4566,  0.2793, -0.4865,  0.5040, -0.6995,  1.5808,  1.2579,\n",
            "        -0.0353,  0.8555, -0.9626,  1.3800, -0.4329,  2.5045, -0.0540, -2.1763,\n",
            "         1.7599,  0.1144, -0.3841, -0.6929, -0.6074,  1.4371, -0.1853, -1.0044,\n",
            "        -0.8496, -0.3266, -1.7892,  0.2947, -0.9695,  1.2488, -1.3763,  0.4803,\n",
            "         0.7801,  1.1124,  0.1927,  0.2877,  0.7960,  0.2902,  0.5956,  0.2125,\n",
            "        -0.9660,  1.1759, -0.7608, -0.8166,  1.4223,  1.3507,  0.1251,  0.3420,\n",
            "         0.9456,  0.2384,  1.4669, -0.0079, -0.2634,  1.2884,  0.9114,  0.6785,\n",
            "         0.7871, -1.2732, -0.8136,  0.6783,  0.8478, -2.0053, -0.2100, -0.8468,\n",
            "        -1.1765, -0.7192,  0.1634, -1.2002,  0.5847, -0.0994,  0.1786,  0.7368,\n",
            "        -1.0057,  2.0974,  1.6705,  0.1553,  0.5119,  0.1653, -0.8831,  1.2920,\n",
            "         0.6210, -0.7722, -0.1652, -1.2688,  0.6914, -1.1334,  0.7620, -0.4927,\n",
            "        -0.1202, -0.9224, -0.4374,  0.0773], grad_fn=<SelectBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This way, when we create our second tower of book words, we know which ones are likely related to a given book"
      ],
      "metadata": {
        "id": "XEMnQMFxzfzZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}